{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Building the network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Fetch the names from the current wikipedia category pages for West Coast and East Cost Hip Hop Musicians\n",
    "def fetch_current_names():\n",
    "    urlWest = 'https://en.wikipedia.org/wiki/Category:West_Coast_hip_hop_musicians'\n",
    "    response = urllib.request.urlopen(urlWest)\n",
    "    data = response.read()      # a `bytes` object\n",
    "    textWest = data.decode('utf-8')\n",
    "    westNames = re.findall('href=\"/wiki/([^:#\"]+)\"', textWest)\n",
    "    urlWest = 'https://en.wikipedia.org/w/index.php?title=Category:West_Coast_hip_hop_musicians&pagefrom=McFedries%2C+Trevor%0ATrevor+McFedries#mw-pages'\n",
    "    response = urllib.request.urlopen(urlWest)\n",
    "    data = response.read()      # a `bytes` object\n",
    "    textWest = data.decode('utf-8')\n",
    "    westNames2 = re.findall('href=\"/wiki/([^:#\"]+)\"', textWest)\n",
    "    westNames = westNames[17:] + westNames2[17:]\n",
    "\n",
    "\n",
    "    urlEast = 'https://en.wikipedia.org/wiki/Category:East_Coast_hip_hop_musicians'\n",
    "    response = urllib.request.urlopen(urlEast)\n",
    "    data = response.read()      # a `bytes` object\n",
    "    textEast = data.decode('utf-8')\n",
    "    eastNames = re.findall('href=\"/wiki/([^:#\"]+)\"', textEast)\n",
    "    urlEast = 'https://en.wikipedia.org/w/index.php?title=Category:East_Coast_hip_hop_musicians&pagefrom=Junglepussy%0AJunglepussy#mw-pages'\n",
    "    response = urllib.request.urlopen(urlEast)\n",
    "    data = response.read()      # a `bytes` object\n",
    "    textWest = data.decode('utf-8')\n",
    "    eastNames2 = re.findall('href=\"/wiki/([^:#\"]+)\"', textWest)\n",
    "    urlEast = 'https://en.wikipedia.org/w/index.php?title=Category:East_Coast_hip_hop_musicians&pagefrom=Stezo#mw-pages'\n",
    "    response = urllib.request.urlopen(urlEast)\n",
    "    data = response.read()      # a `bytes` object\n",
    "    textWest = data.decode('utf-8')\n",
    "    eastNames3 = re.findall('href=\"/wiki/([^:#\"]+)\"', textWest)\n",
    "    eastNames = eastNames[15:] + eastNames2[15:] + eastNames3[15:]\n",
    "    \n",
    "    names = eastNames + westNames\n",
    "    \n",
    "    # Save the combined list of both east and west in a .txt file called \"rappers\"\n",
    "    with open('rappers.txt', 'w') as f:\n",
    "        for item in westNames:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "        for item in eastNames:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    # Save the list of east in a .txt file called \"rappersEast\"\n",
    "    with open('rappersEast.txt', 'w') as f:\n",
    "        for item in eastNames:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    # Save the list of west in a .txt file called \"rappersWest\"\n",
    "    with open('rappersWest.txt', 'w') as f:\n",
    "        for item in westNames:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    return names, eastNames, westNames\n",
    "\n",
    "import json\n",
    "\n",
    "def fetch_wiki_data(rappers, coast):\n",
    "    # Base URL for the Wikipedia API\n",
    "    base_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    \n",
    "    # Determine the directory based on the coast\n",
    "    if coast == \"east\":\n",
    "        directory = 'wikisEast'\n",
    "    elif coast == \"west\":\n",
    "        directory = 'wikisWest'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid coast value. Use either 'east' or 'west'.\")\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Loop through the rapper names\n",
    "    for rapper in rappers:\n",
    "        # Prepare parameters for the API request\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"prop\": \"extracts\",\n",
    "            \"exlimit\": \"1\",\n",
    "            \"explaintext\": \"1\",\n",
    "            \"format\": \"json\",\n",
    "            \"titles\": urllib.parse.quote_plus(rapper.replace(\" \", \"_\"))\n",
    "        }\n",
    "\n",
    "        # Construct the full URL\n",
    "        api_url = base_url + \"?\" + urllib.parse.urlencode(params)\n",
    "        \n",
    "        # Make the request\n",
    "        response = urllib.request.urlopen(api_url)\n",
    "        data = json.loads(response.read().decode('utf-8'))\n",
    "        \n",
    "        # Parse the JSON data to get the 'extract' key\n",
    "        pages = data.get(\"query\", {}).get(\"pages\", {})\n",
    "        for page_id, page_data in pages.items():\n",
    "            content = page_data.get(\"extract\", \"\")\n",
    "            if content:\n",
    "                # Save the content to the appropriate .txt file in the designated directory\n",
    "                with open(f'{directory}/{rapper}.txt', 'w', encoding=\"utf-8\") as f:\n",
    "                    f.write(content)\n",
    "\n",
    "# Example Usage:\n",
    "names, eastNames, westNames = fetch_current_names()\n",
    "fetch_wiki_data(eastNames, \"east\")\n",
    "fetch_wiki_data(westNames, \"west\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "238d335e473a6a0288c3ec44c514c884ceb92e1a1d10b5aca0278d1f0c6277f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
