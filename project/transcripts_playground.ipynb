{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "['A VOICE', 'ARYA', 'BARRISTAN', 'BENJEN', 'BRAN', 'BRONN', 'CASSEL', 'CATELYN', 'CERSEI', 'DAENERYS', 'GARED', 'GUARD1', 'GUARD2', 'ILLYRIO', 'JAIME', 'JON', 'JON/ROBB', 'JORAH', 'JORY', 'KHAL DROGO', 'KING ROBERT', 'LANCEL', 'LITTLEFINGER', 'LORAS', 'LUWIN', 'LYSA', 'MAESTER LUWIN', 'MAID', 'MARILLION', 'MHAEGEN', 'MORD', 'NED', 'PYCELLE', 'RENLY', 'ROBB', 'ROBERT', 'ROBIN', 'RODRIK', 'ROS', 'ROYCE', 'SANDOR', 'SANSA', 'SEPTA MORDANE', 'STEWARD', 'THE HOUND', 'THEON', 'TYRION', 'VARDIS', 'VARYS', 'VAYRS', 'VISERYS', 'WAYMAR ROYCE', 'WILL', 'YOREN', '[ CUT TO']\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the base path for the transcripts directory\n",
    "base_path = './files/Game_of_Thrones_Transcripts'\n",
    "\n",
    "# Regex pattern to match character names\n",
    "pattern = re.compile(r'(.*?):')\n",
    "\n",
    "# Set to store all unique character names\n",
    "all_characters = set()\n",
    "\n",
    "# Loop through each season's folder\n",
    "for season in range(1, 7):  # Assuming there are 8 seasons\n",
    "    season_folder = f\"Season_{season}\"\n",
    "    season_path = os.path.join(base_path, season_folder)\n",
    "    print(\"Hey\")\n",
    "    # Loop through each episode's HTML file\n",
    "    for episode in range(1, 11):  # Assuming there are 10 episodes per season\n",
    "        episode_file = f\"season_{season}_episode_{episode}.html\"\n",
    "        file_path = os.path.join(season_path, episode_file)\n",
    "        print(f\"Season{season}: Episode{episode}\")\n",
    "        # Check if the file exists\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                html_content = file.read()\n",
    "\n",
    "            # Parse the HTML content using BeautifulSoup\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "            # Extract the 'content' class details\n",
    "            content = soup.find_all(class_=\"content\")\n",
    "\n",
    "            # Extract character names\n",
    "            for tag in content:\n",
    "                matches = pattern.findall(tag.get_text())\n",
    "                for match in matches:\n",
    "                    name = match.strip()\n",
    "                    if name.isupper():\n",
    "                        all_characters.add(name)\n",
    "                        print(name)\n",
    "\n",
    "# Print the unique characters\n",
    "print(sorted(all_characters))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
